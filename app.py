## End=to-end Streamlit web app

import streamlit as st
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder
import pandas as pd
import pickle

model=load_model('model.h5')

with open('label_encoder_gender.pkl','rb') as file:
    gen_lab=pickle.load(file)

with open('onehot_encoder_geo.pkl','rb') as file:
    onehot=pickle.load(file)

with open('scaler.pkl','rb') as file:
    scaler=pickle.load(file)

## streamlit app

st.title('Customer Churn Prediction')

##############################################################
### ðŸ“¦ STREAMLIT USER INPUT INTERFACE FOR PREDICTION MODEL ###
##############################################################

# âœ… Assume the following are preloaded using pickle:
# - `onehot` â†’ trained OneHotEncoder for Geography
# - `gen_lab` â†’ trained LabelEncoder for Gender
# - `scaler` â†’ trained StandardScaler for numerical scaling
# - `model` â†’ trained classification model (e.g., ANN, RandomForest)

# ðŸ”· 1. GEOGRAPHY INPUT
# Show dropdown for 'Geography' using the trained OneHotEncoder

# onehot.categories_ returns a list of arrays (1 per column encoded)
# Since we encoded only one column ('Geography'), we use categories_[0] to access it
# e.g., onehot.categories_ â†’ [array(['France', 'Germany', 'Spain'], dtype=object)]
# so, onehot.categories_[0] â†’ ['France', 'Germany', 'Spain']

geography = st.selectbox(
    'Geography',             # ðŸ·ï¸ Label shown on UI
    onehot.categories_[0]    # âœ… Known values learned during training
)

# âœ… GENERAL SYNTAX:
# encoder.categories_[column_index] â†’ returns list of categories for a column (used in OneHotEncoder)

# ðŸ§  WHY WE USE THIS:
# To ensure only known categories (used during model training) are shown to the user.
# If we use an unseen value (e.g., "Italy"), onehot.transform() will raise an error.
# This guarantees compatibility with the encoder.

# â— DO NOT use encoder directly in DataFrame like: pd.DataFrame(onehot)
# Because:
# âž¤ onehot is the **machine** (stamp maker)
# âž¤ You need to use: `geo_encoded = onehot.transform([[geography]])` â†’ This is the **stamped output**
# âž¤ Then wrap in a DataFrame with column names from: onehot.get_feature_names_out(['Geography'])

# âœ… CORRECT WAY (for later step):
# geo_encoded = onehot.transform([[geography]])
# geo_df = pd.DataFrame(geo_encoded, columns=onehot.get_feature_names_out(['Geography']))


# ðŸ”· 2. GENDER INPUT
# Use LabelEncoder to handle gender ('Male', 'Female')
# gen_lab.classes_ returns array of labels it was trained on
# e.g., gen_lab.classes_ â†’ ['Female', 'Male']

gender = st.selectbox(
    'Gender',
    gen_lab.classes_         # âœ… Consistent labels from training
)

# âœ… GENERAL SYNTAX:
# label_encoder.classes_ â†’ returns array of known class labels (used in LabelEncoder)

# ðŸ§  WHY WE USE THIS:
# Again, we want to restrict inputs to known values
# This avoids mismatch errors during: gen_lab.transform([gender])

# âœ… CORRECT WAY (for later step):
# gender_encoded = gen_lab.transform([gender])  # will return [0] or [1] depending on label


# ðŸ”· 3. AGE INPUT (Slider)
age = st.slider(
    'Age',
    min_value=18,
    max_value=92
)

# âœ… GENERAL SYNTAX:
# st.slider('Label', min_value, max_value)

# ðŸŽ¯ Use sliders for bounded integer inputs, like age


# ðŸ”· 4. BALANCE INPUT (Free number input)
balance = st.number_input('Balance')

# âœ… GENERAL SYNTAX:
# st.number_input('Label')


# ðŸ”· 5. CREDIT SCORE
credit_score = st.number_input('Credit Score')


# ðŸ”· 6. ESTIMATED SALARY
estimated_salary = st.number_input('Estimated Salary')


# ðŸ”· 7. TENURE (Slider: 0â€“10 years)
tenure = st.slider('Tenure', 0, 10)


# ðŸ”· 8. NUMBER OF PRODUCTS USED
num_of_products = st.slider('Number of Products', 1, 4)


# ðŸ”· 9. CREDIT CARD STATUS (0 = No, 1 = Yes)
has_cr_card = st.selectbox('Has Credit Card', [0, 1])

# âœ… GENERAL SYNTAX:
# st.selectbox('Label', [options_list])

# ðŸŽ¯ Use selectbox for categorical binary values


# ðŸ”· ðŸ”Ÿ ACTIVE MEMBER STATUS (0 = No, 1 = Yes)
is_active_member = st.selectbox('Is Active Member', [0, 1])


##############################################################
### ðŸ” SUMMARY: ENCODER SYNTAX REFERENCE FOR TRANSFORMATION ###
##############################################################

# ðŸ“˜ OneHotEncoder
# ----------------
# âž¤ onehot.categories_ â†’ list of arrays, each containing unique categories per column
# âž¤ onehot.categories_[0] â†’ gives list of geography categories used during fit()
# âž¤ onehot.transform([[input_value]]) â†’ returns encoded array (e.g., [1, 0, 0])
# âž¤ onehot.get_feature_names_out(['Geography']) â†’ returns encoded column names
#
# ðŸ§  Why use categories_[0]?
# To ensure input matches known values â€” avoids transform errors.
# We need this when taking user input from dropdown so that input is "valid".
#
# ðŸ“˜ LabelEncoder
# ----------------
# âž¤ gen_lab.classes_ â†’ list of class labels (e.g., ['Female', 'Male'])
# âž¤ gen_lab.transform(['Male']) â†’ returns encoded label (e.g., [1])
# âž¤ gen_lab.inverse_transform([1]) â†’ returns label (e.g., 'Male')
#
# ðŸ§  Why use classes_?
# To ensure user selects from valid labels â€” no risk of transform failing.


# ðŸ§  PREPARING INPUT DATA FOR MODEL PREDICTION IN STREAMLIT

# In this Streamlit app, we're collecting user input **one by one** through sliders, dropdowns, etc.

# ðŸ‘‰ These inputs are single values (scalars), like:
#     age = 40
#     credit_score = 600
#     balance = 50000
# But the ML model expects data in the form of a **table** â€” even if it's just one row.
# That means we need to structure the input as a 1-row, multi-column DataFrame.

# âœ… WHY WE USE [ ] AROUND EACH VALUE:
# Wrapping each value in [ ] turns it into a list â†’ which pandas treats as one row.
# Example: [age] â†’ [40] becomes one row with column 'Age'.

# âœ… WHY WE USE gen_lab.transform([gender])[0]:
# LabelEncoder needs input in list form â†’ so we do [gender]
# It returns something like [1] â†’ so we use [0] to extract just the number
# Then we wrap THAT number again in [ ] to make it fit the DataFrame column.

# -----------------------------------------------
# ðŸ” COMPARISON: WHY WE DIDN'T USE [ ] EARLIER?
# -----------------------------------------------
# In earlier notebook-based predictions, we often used:
#     input = [[600, 1, 40, 3, 50000, 2, 1, 1, 60000]]
# That works because:
#     - We manually entered all values in correct order
#     - We already knew the structure
#     - No need for column names if just testing with scaler/model directly

# BUT in Streamlit:
#     - Inputs come from UI fields (not hardcoded)
#     - You build the input row-by-row, value-by-value
#     - So a column-based DataFrame is cleaner, safer, and avoids ordering mistakes

# âœ… Final result: A 1-row DataFrame named `input_data`, ready to merge with encoded geography
# Then we can apply scaling and prediction

input_data = pd.DataFrame({
    'CreditScore': [credit_score],                                 # Turn scalar into 1-row column
    'Gender': [gen_lab.transform([gender])[0]],                    # Encode gender & wrap result in list
    'Age': [age],                                                  # Wrap each value in [ ] to form table row
    'Tenure': [tenure],                                            # Same logic
    'Balance': [balance],                                          # Same logic
    'NumOfProducts': [num_of_products],                            # Same logic
    'HasCrCard': [has_cr_card],                                    # 0 or 1, wrapped in [ ]
    'IsActiveMember': [is_active_member],                          # 0 or 1, wrapped in [ ]
    'EstimatedSalary': [estimated_salary]                          # Final column, wrapped in [ ]
})

# ðŸ“Œ Now `input_data` is a proper table with shape (1, 9)
# You can combine it with one-hot encoded geography, scale it using StandardScaler,
# and feed it into model.predict() to get the output.

# ---------------------------------------------
# ðŸ§  STEP 1: ONE-HOT ENCODE THE SELECTED GEOGRAPHY
# ---------------------------------------------

# The user selected a geography (like 'France') via Streamlit
# Our trained model does not understand raw text labels â€” it was trained using one-hot encoded values.
# So we use the trained OneHotEncoder to convert 'France' into an array like: [[1.0, 0.0, 0.0]]

# âœ… Why double brackets [[geography]]?
# Because OneHotEncoder expects 2D input (rows Ã— columns), 
# even for a single value. So [['France']] works, but ['France'] would raise an error.

geo_enc = onehot.transform([[geography]])


# ---------------------------------------------
# ðŸ§  STEP 2: CONVERT ENCODED OUTPUT TO A DATAFRAME
# ---------------------------------------------

# The result from encoder is a NumPy array like: [[1.0, 0.0, 0.0]]
# But to combine it with our main input data, we need a pandas DataFrame with proper column names.

# âœ… get_feature_names_out(['Geography']) gives us:
# ['Geography_France', 'Geography_Germany', 'Geography_Spain']
# This helps keep the column names clear and consistent with training.

geo_df = pd.DataFrame(
    geo_enc,
    columns=onehot.get_feature_names_out(['Geography'])
)


# ---------------------------------------------
# ðŸ§  STEP 3: CONCAT THE ENCODED GEOGRAPHY WITH THE MAIN INPUT DATA
# ---------------------------------------------

# Now we add the one-hot encoded geography columns to our main `input_data` DataFrame.

# âœ… Why not drop "Geography" before adding geo_df?
# Because our `input_data` never had a 'Geography' column to begin with!
# We had collected it separately and encoded it directly â€” so there's nothing to remove.

# âš ï¸ If you tried to do:
# input_data.drop("Geography", axis=1)
# You'd get: KeyError: "['Geography'] not found in axis"

# âœ… Why reset_index(drop=True)?
# This ensures both DataFrames (input_data and geo_df) have matching row indices (0 in this case),
# so that the merge works cleanly â€” otherwise, pandas may misalign rows or insert NaNs.

# âœ… axis=1 means we are concatenating column-wise (left-to-right), not row-wise (top-to-bottom)

input_data = pd.concat(
    [input_data.reset_index(drop=True), geo_df],  # combine original inputs + encoded geography
    axis=1
)

# âœ… Final Result: input_data now includes all model-ready features:
# - Numeric fields like CreditScore, Age, Salary...
# - Encoded 'Gender'
# - One-hot encoded 'Geography'
# Now it's ready to be scaled and passed into model.predict()


input_data_scaled=scaler.transform(input_data)

prediction=model.predict(input_data_scaled)

pred_prob=prediction[0][0] ## multidimensional array

if pred_prob>0.5:
    st.write("Customer is likely to churn")
else:
    st.write("Customer is not likely to churn")

st.write(f"Churn probability: {pred_prob:.2f}")