{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456c63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fc5b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the dataset\n",
    "\n",
    "data=pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()##Prints the initial few records records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d791a1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0.00\n",
       "1        83807.86\n",
       "2       159660.80\n",
       "3            0.00\n",
       "4       125510.82\n",
       "          ...    \n",
       "9995         0.00\n",
       "9996     57369.61\n",
       "9997         0.00\n",
       "9998     75075.31\n",
       "9999    130142.79\n",
       "Name: Balance, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55e00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the data, Drop irrelevant features\n",
    "\n",
    "data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "\n",
    "##Error because the columns have been deleted in first run so during the second run it is showing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5b0e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3603815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France       0   42       2       0.00              1   \n",
       "1             608     Spain       0   41       1   83807.86              1   \n",
       "2             502    France       0   42       8  159660.80              3   \n",
       "3             699    France       0   39       1       0.00              2   \n",
       "4             850     Spain       0   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France       1   39       5       0.00              2   \n",
       "9996          516    France       1   35      10   57369.61              1   \n",
       "9997          709    France       0   36       7       0.00              1   \n",
       "9998          772   Germany       1   42       3   75075.31              2   \n",
       "9999          792    France       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encode categorical variable\n",
    "label_encoder_gender=LabelEncoder()\n",
    "data['Gender']=label_encoder_gender.fit_transform(data['Gender'])\n",
    "data  \n",
    "## Female-0, Male-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed17c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "      Geography_France  Geography_Germany  Geography_Spain\n",
      "0                  1.0                0.0              0.0\n",
      "1                  0.0                0.0              1.0\n",
      "2                  1.0                0.0              0.0\n",
      "3                  1.0                0.0              0.0\n",
      "4                  0.0                0.0              1.0\n",
      "...                ...                ...              ...\n",
      "9995               1.0                0.0              0.0\n",
      "9996               1.0                0.0              0.0\n",
      "9997               1.0                0.0              0.0\n",
      "9998               0.0                1.0              0.0\n",
      "9999               1.0                0.0              0.0\n",
      "\n",
      "[10000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "##Onehot encode 'Geography' \n",
    "##Can't use LabelEncoder because the categories aren't binary, there are more than 2 categories, so 0,1,2 so the model will interpret it as Germany>France>Spain, which is an absurd assumption, hence here we need one hot encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotgeo=OneHotEncoder(sparse_output=False) ## Won't give sparse matrix -- matrix with mostly zeros and few non-zeros, sparse matrix stores the positions of non-zero values onl to save memory\n",
    "geoenc=onehotgeo.fit_transform(data[['Geography']]) ## Always double bracket as 2D matrix mandatory\n",
    "col=onehotgeo.get_feature_names_out()\n",
    "geo_df=pd.DataFrame(geoenc,columns=col)\n",
    "print(geoenc)\n",
    "print(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab0ea80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine one hot encoded columsn with the original data\n",
    "\n",
    "data=pd.concat([data.drop('Geography',axis=1),geo_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880efbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9703d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the encoders and scaler\n",
    "\n",
    "with open('label_encoder_gender.pkl','wb') as file:\n",
    "    pickle.dump(label_encoder_gender,file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl','wb') as file:\n",
    "    pickle.dump(onehotgeo,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48263d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n📦 WHY WE USE PICKLE FOR ENCODERS IN MACHINE LEARNING\\n\\nIn machine learning, categorical columns (like \\'Gender\\' or \\'Geography\\') must be converted into numerical form\\nbecause models can only process numbers. This is typically done using encoders like:\\n\\n- LabelEncoder: Converts categories into numeric labels (e.g., Male → 1, Female → 0)\\n- OneHotEncoder: Converts categories into binary vectors (e.g., France → [1,0,0], Germany → [0,1,0], etc.)\\n\\nOnce these encoders are trained (i.e., \"fitted\" on the dataset), we should save them for future use so that:\\n- We don’t need to retrain them every time\\n- We prevent mismatched encodings that could break predictions\\n\\nThis saving process is called **Pickling**, and it\\'s done using Python’s built-in `pickle` module.\\nIt serializes (saves) Python objects to a file in binary format.\\n\\n--------------------------------------------------------------------------------\\n💾 SAVING (PICKLING) THE ENCODERS AFTER FITTING (AS COMMENTS)\\n--------------------------------------------------------------------------------\\n\\n# import pickle\\n\\n# Save the trained LabelEncoder for \\'Gender\\'\\n# with open(\\'label_encoder_gender.pkl\\', \\'wb\\') as file:\\n#     pickle.dump(label_encoder_gender, file)\\n\\n# Save the trained OneHotEncoder for \\'Geography\\'\\n# with open(\\'onehot_encoder_geo.pkl\\', \\'wb\\') as file:\\n#     pickle.dump(onehotgeo, file)\\n\\n→ \\'wb\\' stands for \"write binary\"\\n→ `pickle.dump()` stores the object to a file\\n\\n--------------------------------------------------------------------------------\\n📥 LOADING (UNPICKLING) THE ENCODERS LATER DURING INFERENCE (AS COMMENTS)\\n--------------------------------------------------------------------------------\\n\\n# import pickle\\n\\n# Load the saved LabelEncoder for \\'Gender\\'\\n# with open(\\'label_encoder_gender.pkl\\', \\'rb\\') as file:\\n#     label_encoder_gender = pickle.load(file)\\n\\n# Load the saved OneHotEncoder for \\'Geography\\'\\n# with open(\\'onehot_encoder_geo.pkl\\', \\'rb\\') as file:\\n#     onehotgeo = pickle.load(file)\\n\\n→ \\'rb\\' stands for \"read binary\"\\n→ `pickle.load()` reads the file and brings the object back into memory\\n\\n--------------------------------------------------------------------------------\\n✅ WHY THIS IS IMPORTANT IN REAL-WORLD ML PIPELINES\\n--------------------------------------------------------------------------------\\n\\n- Ensures that training and inference pipelines use the SAME transformation logic\\n- Avoids retraining or errors due to different category mappings\\n- Makes your code production-ready, reliable, and scalable\\n- Especially useful when deploying models as APIs, microservices, or apps\\n\\nConclusion: Always pickle your encoders, scalers, or any transformation logic after fitting,\\nand load them back before making predictions on new data. It ensures repeatability, efficiency,\\nand reliability in your ML workflow.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "📦 WHY WE USE PICKLE FOR ENCODERS IN MACHINE LEARNING\n",
    "\n",
    "In machine learning, categorical columns (like 'Gender' or 'Geography') must be converted into numerical form\n",
    "because models can only process numbers. This is typically done using encoders like:\n",
    "\n",
    "- LabelEncoder: Converts categories into numeric labels (e.g., Male → 1, Female → 0)\n",
    "- OneHotEncoder: Converts categories into binary vectors (e.g., France → [1,0,0], Germany → [0,1,0], etc.)\n",
    "\n",
    "Once these encoders are trained (i.e., \"fitted\" on the dataset), we should save them for future use so that:\n",
    "- We don’t need to retrain them every time\n",
    "- We prevent mismatched encodings that could break predictions\n",
    "\n",
    "This saving process is called **Pickling**, and it's done using Python’s built-in `pickle` module.\n",
    "It serializes (saves) Python objects to a file in binary format.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "💾 SAVING (PICKLING) THE ENCODERS AFTER FITTING (AS COMMENTS)\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# Save the trained LabelEncoder for 'Gender'\n",
    "# with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "#     pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "# Save the trained OneHotEncoder for 'Geography'\n",
    "# with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "#     pickle.dump(onehotgeo, file)\n",
    "\n",
    "→ 'wb' stands for \"write binary\"\n",
    "→ `pickle.dump()` stores the object to a file\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "📥 LOADING (UNPICKLING) THE ENCODERS LATER DURING INFERENCE (AS COMMENTS)\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# Load the saved LabelEncoder for 'Gender'\n",
    "# with open('label_encoder_gender.pkl', 'rb') as file:\n",
    "#     label_encoder_gender = pickle.load(file)\n",
    "\n",
    "# Load the saved OneHotEncoder for 'Geography'\n",
    "# with open('onehot_encoder_geo.pkl', 'rb') as file:\n",
    "#     onehotgeo = pickle.load(file)\n",
    "\n",
    "→ 'rb' stands for \"read binary\"\n",
    "→ `pickle.load()` reads the file and brings the object back into memory\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "✅ WHY THIS IS IMPORTANT IN REAL-WORLD ML PIPELINES\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "- Ensures that training and inference pipelines use the SAME transformation logic\n",
    "- Avoids retraining or errors due to different category mappings\n",
    "- Makes your code production-ready, reliable, and scalable\n",
    "- Especially useful when deploying models as APIs, microservices, or apps\n",
    "\n",
    "Conclusion: Always pickle your encoders, scalers, or any transformation logic after fitting,\n",
    "and load them back before making predictions on new data. It ensures repeatability, efficiency,\n",
    "and reliability in your ML workflow.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55da2b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1975c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Split dataset into independent (X) and dependent (Y) features\n",
    "X = data.drop('Exited', axis=1)  # Features used to predict (e.g., age, salary, credit score)\n",
    "Y = data['Exited']               # Target variable (whether the customer exited or not)\n",
    "\n",
    "# ✅ Split the data into training and testing sets\n",
    "# test_size=0.2 → 20% of data will be used for testing\n",
    "# random_state=42 → sets a seed so the same random split happens every time (for reproducibility)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Feature Scaling\n",
    "# ⚠️ Why scale? Many ML models are sensitive to the scale of features.\n",
    "#    For example, 'Age' might range from 18 to 100, while 'Balance' might go up to 1,000,000.\n",
    "#    Models like logistic regression, SVM, neural networks, and KNN can give undue importance\n",
    "#    to features with larger numerical values.\n",
    "\n",
    "# 🎯 Intuition:\n",
    "#    Imagine a race between a swimmer, runner, and cyclist—but you measure them in different units (laps, km, pedal strokes).\n",
    "#    It's unfair unless you bring them all to the same unit.\n",
    "#    Similarly, we scale all features to the same standard scale (mean = 0, std = 1) so the model can treat them equally.\n",
    "\n",
    "# ✅ StandardScaler standardizes each feature by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler (trained on training data) to transform test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ⚠️ Note: Never fit the scaler on test data — this avoids data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f425bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37639499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the saved LabelEncoder for 'Gender'\n",
    "with open('label_encoder_gender.pkl', 'rb') as file:\n",
    "    label_encoder_gender = pickle.load(file)\n",
    "\n",
    "# Load the saved OneHotEncoder for 'Geography'\n",
    "with open('onehot_encoder_geo.pkl', 'rb') as file:\n",
    "    onehotgeo = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a407e",
   "metadata": {},
   "source": [
    "ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ebd78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Harjeet Singh Pannu\\Desktop\\ANN project\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as ts\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c19ff38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],) ## X_train.shape[0] -- no. of rows, X_train.shape[1] -- no. of columns\n",
    "\n",
    "## (,) -- tuple to signify the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c2283ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Harjeet Singh Pannu\\Desktop\\ANN project\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Build our ANN Model\n",
    "model=Sequential([\n",
    "    Dense(64,activation='relu',input_shape=(X_train.shape[1],)), ## HL1(Hidden Layer 1, 64 neurons) connected with input layer\n",
    "    Dense(32,activation='relu'), ## HL2(Hidden Layer 2, 32 neurons), no input connection so no input_shape needed\n",
    "    Dense(1,activation='sigmoid') ## output layer(1 neuron), sigmoid used as binary classification (0 or 1)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94facf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7537507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📌 MODEL COMPILATION IN TENSORFLOW / KERAS\n",
    "\n",
    "🔹 General Syntax:\n",
    "model.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=LOSS_FUNCTION,\n",
    "    metrics=[LIST_OF_METRICS]\n",
    ")\n",
    "\n",
    "🔸 Parameters:\n",
    "- optimizer: Algorithm to update model weights (e.g., \"adam\", \"sgd\", or a custom optimizer like Adam(learning_rate=0.01))\n",
    "- loss: Function to calculate how wrong the model is (e.g., \"binary_crossentropy\", \"mse\", \"sparse_categorical_crossentropy\")\n",
    "- metrics: List of metrics to monitor during training (e.g., [\"accuracy\"], [\"mae\"])\n",
    "\n",
    "-------------------------------------------------------\n",
    "✅ Examples:\n",
    "-------------------------------------------------------\n",
    "\n",
    "1. 🔹 Binary Classification (e.g., predict 0 or 1):\n",
    "Used when the target variable has 2 classes.\n",
    "\"\"\"\n",
    "import tensorflow\n",
    "opt=tensorflow.keras.optimizers.Adam(learning_rate=0.01) ## many optimizers are there apart from Adam\n",
    "lo=tensorflow.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91c09da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile the model\n",
    "\n",
    "model.compile(optimizer=opt,loss=lo,metrics=['accuracy']) ## for binary classification this is there, for multi-classification -- sparse cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc8574cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Harjeet Singh Pannu\\Desktop\\ANN project\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## compile the model\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy']) ## for binary classification this is there, for multi-classification -- sparse cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dd95ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📌 SETTING UP TENSORBOARD IN KERAS / TENSORFLOW — FULL INTUITION WITH CODE AND COMMENTS\n",
    "\n",
    "-------------------------------------------------------\n",
    "🔹 PURPOSE:\n",
    "TensorBoard is a visualization tool that lets us monitor the training of our model.\n",
    "It provides graphs for:\n",
    "- Loss & accuracy over epochs\n",
    "- Histograms of weights and biases\n",
    "- Model graph structure\n",
    "- Learning rate trends\n",
    "-------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# 🔸 STEP 1: Import necessary modules\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import datetime\n",
    "\n",
    "\"\"\"\n",
    "We import:\n",
    "- TensorBoard: for logging training stats\n",
    "- EarlyStopping: (optional) stops training early if no improvement\n",
    "- datetime: to create unique folder names based on current date & time\n",
    "\"\"\"\n",
    "\n",
    "# 🔸 STEP 2: Create a unique log directory for TensorBoard using datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\"\"\"\n",
    "📍 Intuition Behind datetime:\n",
    "- datetime.datetime.now() gives the current date and time.\n",
    "- strftime(\"%Y%m%d-%H%M%S\") formats it as:\n",
    "    %Y → Year   (e.g., 2025)\n",
    "    %m → Month  (e.g., 08)\n",
    "    %d → Day    (e.g., 03)\n",
    "    %H → Hour   (24hr format)\n",
    "    %M → Minute\n",
    "    %S → Second\n",
    "- So, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  might return something like \"20250803-225612\"\n",
    "- This makes your log folder: logs/fit20250803-225612\n",
    "- Each training run has a unique folder → logs don’t overwrite\n",
    "\"\"\"\n",
    "\n",
    "# 🔸 STEP 3: Initialize TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,        # where logs will be stored\n",
    "    histogram_freq=1,       # log histograms every epoch\n",
    "    write_graph=True,       # log the computational graph\n",
    "    write_images=False      # optionally log model weights as images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2ddfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n-------------------------------------------------------\\n🔹 USAGE IN TRAINING:\\nJust pass it as a callback to model.fit()\\n\\nmodel.fit(\\n    X_train, Y_train,\\n    epochs=100,\\n    validation_data=(X_test, Y_test),\\n    callbacks=[early_stopping_callback]\\n)\\n\\n-------------------------------------------------------\\n🔸 MONITOR OPTIONS:\\n- 'val_loss': Most common, looks at validation loss\\n- 'val_accuracy': For classification tasks\\n\\n🔸 PATIENCE:\\n- Number of epochs to allow for no improvement\\n- E.g., if patience=5, training stops if no better result in 5 rounds\\n\\n🔸 RESTORE_BEST_WEIGHTS:\\n- True = after stopping, model weights will revert to the best epoch\\n- False = model keeps the weights from the last epoch (not recommended)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "📌 EARLY STOPPING IN KERAS / TENSORFLOW — FULL EXPLANATION WITH COMMENTS & GENERAL SYNTAX\n",
    "\n",
    "🔹 WHAT IS EARLY STOPPING?\n",
    "EarlyStopping is a built-in Keras callback that:\n",
    "→ Monitors model performance during training\n",
    "→ Stops training when it detects no further improvement\n",
    "→ Optionally restores the model weights from the best epoch\n",
    "\n",
    "This is useful for:\n",
    "✅ Preventing overfitting\n",
    "✅ Saving time and compute\n",
    "✅ Automatically picking the best version of the model\n",
    "\n",
    "-------------------------------------------------------\n",
    "🔹 GENERAL SYNTAX:\n",
    "\n",
    "EarlyStopping(\n",
    "    monitor='val_loss',          # Metric to monitor ('val_loss', 'val_accuracy', etc.)\n",
    "    patience=5,                  # Number of epochs to wait before stopping if no improvement\n",
    "    restore_best_weights=True,  # Restore model weights from the best epoch\n",
    "    min_delta=0,                # Minimum change to qualify as an improvement (optional)\n",
    "    mode='auto',                # 'auto', 'min', or 'max' — auto figures out based on monitored metric\n",
    "    verbose=1                   # Show logs when training stops (optional)\n",
    ")\n",
    "\n",
    "-------------------------------------------------------\n",
    "🔹 EXAMPLE SETUP:\n",
    "\"\"\"\n",
    "\n",
    "# 🔸 Import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 🔸 Define the callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',          # Stop training when validation loss stops improving\n",
    "    patience=10,                  # Wait 5 epochs for improvement\n",
    "    restore_best_weights=True,  # Revert to best model after stopping\n",
    "    verbose=1                   # Print message when training is stopped\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------\n",
    "🔹 USAGE IN TRAINING:\n",
    "Just pass it as a callback to model.fit()\n",
    "\n",
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "-------------------------------------------------------\n",
    "🔸 MONITOR OPTIONS:\n",
    "- 'val_loss': Most common, looks at validation loss\n",
    "- 'val_accuracy': For classification tasks\n",
    "\n",
    "🔸 PATIENCE:\n",
    "- Number of epochs to allow for no improvement\n",
    "- E.g., if patience=5, training stops if no better result in 5 rounds\n",
    "\n",
    "🔸 RESTORE_BEST_WEIGHTS:\n",
    "- True = after stopping, model weights will revert to the best epoch\n",
    "- False = model keeps the weights from the last epoch (not recommended)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb0fcb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\Harjeet Singh Pannu\\Desktop\\ANN project\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Harjeet Singh Pannu\\Desktop\\ANN project\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8040 - val_loss: 0.3926 - val_accuracy: 0.8380\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8456 - val_loss: 0.3568 - val_accuracy: 0.8545\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8543 - val_loss: 0.3449 - val_accuracy: 0.8590\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8576 - val_loss: 0.3457 - val_accuracy: 0.8565\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8606 - val_loss: 0.3445 - val_accuracy: 0.8600\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8612 - val_loss: 0.3428 - val_accuracy: 0.8580\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8615 - val_loss: 0.3417 - val_accuracy: 0.8590\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8622 - val_loss: 0.3379 - val_accuracy: 0.8590\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8631 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8639 - val_loss: 0.3422 - val_accuracy: 0.8600\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8627 - val_loss: 0.3392 - val_accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8675 - val_loss: 0.3388 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8665 - val_loss: 0.3391 - val_accuracy: 0.8625\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8658 - val_loss: 0.3363 - val_accuracy: 0.8635\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8680 - val_loss: 0.3397 - val_accuracy: 0.8620\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8691 - val_loss: 0.3440 - val_accuracy: 0.8585\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8674 - val_loss: 0.3428 - val_accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8698 - val_loss: 0.3410 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8684 - val_loss: 0.3442 - val_accuracy: 0.8615\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8699 - val_loss: 0.3432 - val_accuracy: 0.8570\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8717 - val_loss: 0.3457 - val_accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8730 - val_loss: 0.3414 - val_accuracy: 0.8590\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8710 - val_loss: 0.3420 - val_accuracy: 0.8590\n",
      "Epoch 24/100\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.8706Restoring model weights from the end of the best epoch: 14.\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8720 - val_loss: 0.3388 - val_accuracy: 0.8650\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[tensorboard_callback,early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "226fb3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n📦 SAVING MODELS: .h5 VS .pkl FILES — FULL INTUITION & USAGE EXPLAINED\\n\\n----------------------------------------------------------\\n🔹 WHAT IS A `.h5` FILE?\\n----------------------------------------------------------\\n- `.h5` stands for Hierarchical Data Format version 5\\n- It is used in TensorFlow/Keras to save an entire deep learning model\\n- This includes:\\n  ✅ Model architecture (layers, activations)\\n  ✅ Trained weights\\n  ✅ Training configuration (optimizer, loss)\\n  ✅ Optimizer state (to resume training seamlessly)\\n\\n📌 Usage:\\n- Save a model:      model.save(\"model_name.h5\")\\n- Load a model:      model = load_model(\"model_name.h5\")\\n\\n----------------------------------------------------------\\n🔹 WHAT IS A `.pkl` FILE?\\n----------------------------------------------------------\\n- `.pkl` is a Python Pickle file — used to serialize and save general Python objects\\n- Commonly used for:\\n  ✅ Scikit-learn models (RandomForest, XGBoost, etc.)\\n  ✅ Preprocessors like LabelEncoder, OneHotEncoder\\n  ✅ Scalers like StandardScaler, MinMaxScaler\\n  ✅ Python lists, dicts, etc.\\n\\n📌 Usage:\\n- Save an object:    pickle.dump(object, file)\\n- Load an object:    object = pickle.load(file)\\n\\n----------------------------------------------------------\\n🔸 COMPARISON TABLE\\n\\n| Feature               | .h5 (HDF5 Format)                  | .pkl (Pickle Format)                   |\\n|-----------------------|------------------------------------|----------------------------------------|\\n| Purpose               | Save deep learning models          | Save any Python object                 |\\n| Format Type           | Hierarchical data structure        | Python-specific serialization          |\\n| Usage Library         | TensorFlow / Keras                 | Python / sklearn / preprocessing       |\\n| Language Independent  | ✅ Yes (readable in other tools)   | ❌ No (Python-specific)                |\\n| Contents              | Model + weights + optimizer state  | Any Python object (model, encoder, etc.) |\\n\\n----------------------------------------------------------\\n🔹 WHEN TO USE WHAT?\\n\\n✅ Use `.h5` when working with deep learning (Keras/TensorFlow) models  \\n✅ Use `.pkl` when saving preprocessing objects, scikit-learn models, or general Python structures\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "📦 SAVING MODELS: .h5 VS .pkl FILES — FULL INTUITION & USAGE EXPLAINED\n",
    "\n",
    "----------------------------------------------------------\n",
    "🔹 WHAT IS A `.h5` FILE?\n",
    "----------------------------------------------------------\n",
    "- `.h5` stands for Hierarchical Data Format version 5\n",
    "- It is used in TensorFlow/Keras to save an entire deep learning model\n",
    "- This includes:\n",
    "  ✅ Model architecture (layers, activations)\n",
    "  ✅ Trained weights\n",
    "  ✅ Training configuration (optimizer, loss)\n",
    "  ✅ Optimizer state (to resume training seamlessly)\n",
    "\n",
    "📌 Usage:\n",
    "- Save a model:      model.save(\"model_name.h5\")\n",
    "- Load a model:      model = load_model(\"model_name.h5\")\n",
    "\n",
    "----------------------------------------------------------\n",
    "🔹 WHAT IS A `.pkl` FILE?\n",
    "----------------------------------------------------------\n",
    "- `.pkl` is a Python Pickle file — used to serialize and save general Python objects\n",
    "- Commonly used for:\n",
    "  ✅ Scikit-learn models (RandomForest, XGBoost, etc.)\n",
    "  ✅ Preprocessors like LabelEncoder, OneHotEncoder\n",
    "  ✅ Scalers like StandardScaler, MinMaxScaler\n",
    "  ✅ Python lists, dicts, etc.\n",
    "\n",
    "📌 Usage:\n",
    "- Save an object:    pickle.dump(object, file)\n",
    "- Load an object:    object = pickle.load(file)\n",
    "\n",
    "----------------------------------------------------------\n",
    "🔸 COMPARISON TABLE\n",
    "\n",
    "| Feature               | .h5 (HDF5 Format)                  | .pkl (Pickle Format)                   |\n",
    "|-----------------------|------------------------------------|----------------------------------------|\n",
    "| Purpose               | Save deep learning models          | Save any Python object                 |\n",
    "| Format Type           | Hierarchical data structure        | Python-specific serialization          |\n",
    "| Usage Library         | TensorFlow / Keras                 | Python / sklearn / preprocessing       |\n",
    "| Language Independent  | ✅ Yes (readable in other tools)   | ❌ No (Python-specific)                |\n",
    "| Contents              | Model + weights + optimizer state  | Any Python object (model, encoder, etc.) |\n",
    "\n",
    "----------------------------------------------------------\n",
    "🔹 WHEN TO USE WHAT?\n",
    "\n",
    "✅ Use `.h5` when working with deep learning (Keras/TensorFlow) models  \n",
    "✅ Use `.pkl` when saving preprocessing objects, scikit-learn models, or general Python structures\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6d80141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harjeet Singh Pannu\\Desktop\\ANN project\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825b6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Tensorboard Extension\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2f277f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16716), started 1 day, 14:23:10 ago. (Use '!kill 16716' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7112cbdf42864f01\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7112cbdf42864f01\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
